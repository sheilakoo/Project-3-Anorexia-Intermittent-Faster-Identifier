{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba814277",
   "metadata": {},
   "source": [
    "**Previous:** [Part 3 - Exploratory Data Analysis (EDA)](Part%203%20-%20Exploratory%20Data%20Analysis%20(EDA).ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e995b0b",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Reddit Webscraping\n",
    "\n",
    "## Part 4 - Pre-processing & Modelling\n",
    "\n",
    "---\n",
    "## Contents\n",
    "---\n",
    "\n",
    "### [Part 1 - Web Scraping](Part%201%20-%20Web%20Scraping.ipynb)\n",
    "1. Introduction\n",
    "2. Import - Web Scraping using PRAW\n",
    "\n",
    "### [Part 2 - Data Cleaning](Part%202%20-%20Data%20Cleaning.ipynb)\n",
    "1. Import\n",
    "2. Cleaning - Data Frame and Text\n",
    "\n",
    "### [Part 3 - Exploratory Data Analysis (EDA)](Part%203%20-%20Exploratory%20Data%20Analysis%20(EDA).ipynb)\n",
    "1. Import\n",
    "2. Exploratory Data Analysis - Trends\n",
    "3. Exploratory Data Analysis - Unigrams \n",
    "4. Exploratory Data Analysis - Bigrams\n",
    "5. Exploratory Data Analysis - Trigrams \n",
    "\n",
    "### [Part 4 - Pre-processing & Modelling](Part%204%20-%20Pre-processing%20&%20Modelling.ipynb)\n",
    "1. [Import](#1.-Import)\n",
    "2. [Pre-processing - Binarizing The 2 Classes, Train-test Split](#2.-Pre-processing)\n",
    "3. [Modelling - Feature Engineering, Comparing Against Other Models](#3.-Modelling)\n",
    "4. [Conclusion - Summary, Recommendations](#4.-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9cc72",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import\n",
    "---\n",
    "### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a201e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e7a07",
   "metadata": {},
   "source": [
    "### 1.2 Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd1676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>total_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_type</th>\n",
       "      <th>time_uploaded</th>\n",
       "      <th>title_&amp;_text</th>\n",
       "      <th>title_text_stemmed</th>\n",
       "      <th>title_text_lemmatized</th>\n",
       "      <th>stemmed_round_1</th>\n",
       "      <th>lemmatized_round_1</th>\n",
       "      <th>stemmed_round_2</th>\n",
       "      <th>lemmatized_round_2</th>\n",
       "      <th>stemmed_round_3</th>\n",
       "      <th>lemmatized_round_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>26/9/23 7:57</td>\n",
       "      <td>Does taking flavoured creatine break a fast Ta...</td>\n",
       "      <td>['take', 'flavour', 'creatin', 'break', 'fast'...</td>\n",
       "      <td>['taking', 'flavoured', 'creatine', 'break', '...</td>\n",
       "      <td>['take', 'flavour', 'creatin', 'break', 'fast'...</td>\n",
       "      <td>['taking', 'flavoured', 'creatine', 'break', '...</td>\n",
       "      <td>['take', 'flavour', 'creatin', 'break', 'fast'...</td>\n",
       "      <td>['taking', 'flavoured', 'creatine', 'break', '...</td>\n",
       "      <td>['take', 'flavour', 'creatin', 'break', 'fast'...</td>\n",
       "      <td>['taking', 'flavoured', 'creatine', 'break', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>26/9/23 7:46</td>\n",
       "      <td>I lost 120 lbsshe lost 80 One meal a day from ...</td>\n",
       "      <td>['120', 'lbsshe', '80', 'meal', '']</td>\n",
       "      <td>['120', 'lbsshe', '80', 'meal', '']</td>\n",
       "      <td>['lost', '120', 'lbsshe', 'lost', '80', 'one',...</td>\n",
       "      <td>['lost', '120', 'lbsshe', 'lost', '80', 'one',...</td>\n",
       "      <td>['lost', '120', 'lbsshe', 'lost', '80', 'one',...</td>\n",
       "      <td>['lost', '120', 'lbsshe', 'lost', '80', 'one',...</td>\n",
       "      <td>['lost', '120', 'lbsshe', 'lost', '80', 'one',...</td>\n",
       "      <td>['lost', '120', 'lbsshe', 'lost', '80', 'one',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>26/9/23 6:10</td>\n",
       "      <td>Does fasting out of spite work Well see in 4 w...</td>\n",
       "      <td>['fast', 'spite', 'work', '4', 'week', 'wed', ...</td>\n",
       "      <td>['fasting', 'spite', 'work', '4', 'week', 'wed...</td>\n",
       "      <td>['fast', 'spite', 'see', '4', 'week', 'go', 'w...</td>\n",
       "      <td>['fasting', 'spite', 'see', '4', 'week', 'go',...</td>\n",
       "      <td>['fast', 'spite', 'work', 'see', '4', 'week', ...</td>\n",
       "      <td>['fasting', 'spite', 'work', 'see', '4', 'week...</td>\n",
       "      <td>['fast', 'spite', 'work', 'see', '4', 'week', ...</td>\n",
       "      <td>['fasting', 'spite', 'work', 'see', '4', 'week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>26/9/23 6:00</td>\n",
       "      <td>Daily Fasting Checkin  Type of fast water juic...</td>\n",
       "      <td>['daili', 'fast', 'checkin', 'type', 'fast', '...</td>\n",
       "      <td>['daily', 'fasting', 'checkin', 'type', 'fast'...</td>\n",
       "      <td>['daili', 'fast', 'checkin', 'type', 'fast', '...</td>\n",
       "      <td>['daily', 'fasting', 'checkin', 'type', 'fast'...</td>\n",
       "      <td>['daili', 'fast', 'checkin', 'type', 'fast', '...</td>\n",
       "      <td>['daily', 'fasting', 'checkin', 'type', 'fast'...</td>\n",
       "      <td>['daili', 'fast', 'checkin', 'type', 'fast', '...</td>\n",
       "      <td>['daily', 'fasting', 'checkin', 'type', 'fast'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>26/9/23 4:10</td>\n",
       "      <td>90 Days of Intermittent Fasting  IT WORKS Hi E...</td>\n",
       "      <td>['90', 'intermitt', 'fast', 'work', 'hi', 'eve...</td>\n",
       "      <td>['90', 'intermittent', 'fasting', 'work', 'hi'...</td>\n",
       "      <td>['90', 'day', 'intermitt', 'fast', 'work', 'hi...</td>\n",
       "      <td>['90', 'day', 'intermittent', 'fasting', 'work...</td>\n",
       "      <td>['90', 'day', 'intermitt', 'fast', 'work', 'hi...</td>\n",
       "      <td>['90', 'day', 'intermittent', 'fasting', 'work...</td>\n",
       "      <td>['90', 'day', 'intermitt', 'fast', 'work', 'hi...</td>\n",
       "      <td>['90', 'day', 'intermittent', 'fasting', 'work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  total_comments            subreddit post_type time_uploaded  \\\n",
       "0      1               0  intermittentfasting       new  26/9/23 7:57   \n",
       "1      6               1  intermittentfasting       new  26/9/23 7:46   \n",
       "2      0               2  intermittentfasting       new  26/9/23 6:10   \n",
       "3      1               0  intermittentfasting       new  26/9/23 6:00   \n",
       "4     17               8  intermittentfasting       new  26/9/23 4:10   \n",
       "\n",
       "                                        title_&_text  \\\n",
       "0  Does taking flavoured creatine break a fast Ta...   \n",
       "1  I lost 120 lbsshe lost 80 One meal a day from ...   \n",
       "2  Does fasting out of spite work Well see in 4 w...   \n",
       "3  Daily Fasting Checkin  Type of fast water juic...   \n",
       "4  90 Days of Intermittent Fasting  IT WORKS Hi E...   \n",
       "\n",
       "                                  title_text_stemmed  \\\n",
       "0  ['take', 'flavour', 'creatin', 'break', 'fast'...   \n",
       "1                ['120', 'lbsshe', '80', 'meal', '']   \n",
       "2  ['fast', 'spite', 'work', '4', 'week', 'wed', ...   \n",
       "3  ['daili', 'fast', 'checkin', 'type', 'fast', '...   \n",
       "4  ['90', 'intermitt', 'fast', 'work', 'hi', 'eve...   \n",
       "\n",
       "                               title_text_lemmatized  \\\n",
       "0  ['taking', 'flavoured', 'creatine', 'break', '...   \n",
       "1                ['120', 'lbsshe', '80', 'meal', '']   \n",
       "2  ['fasting', 'spite', 'work', '4', 'week', 'wed...   \n",
       "3  ['daily', 'fasting', 'checkin', 'type', 'fast'...   \n",
       "4  ['90', 'intermittent', 'fasting', 'work', 'hi'...   \n",
       "\n",
       "                                     stemmed_round_1  \\\n",
       "0  ['take', 'flavour', 'creatin', 'break', 'fast'...   \n",
       "1  ['lost', '120', 'lbsshe', 'lost', '80', 'one',...   \n",
       "2  ['fast', 'spite', 'see', '4', 'week', 'go', 'w...   \n",
       "3  ['daili', 'fast', 'checkin', 'type', 'fast', '...   \n",
       "4  ['90', 'day', 'intermitt', 'fast', 'work', 'hi...   \n",
       "\n",
       "                                  lemmatized_round_1  \\\n",
       "0  ['taking', 'flavoured', 'creatine', 'break', '...   \n",
       "1  ['lost', '120', 'lbsshe', 'lost', '80', 'one',...   \n",
       "2  ['fasting', 'spite', 'see', '4', 'week', 'go',...   \n",
       "3  ['daily', 'fasting', 'checkin', 'type', 'fast'...   \n",
       "4  ['90', 'day', 'intermittent', 'fasting', 'work...   \n",
       "\n",
       "                                     stemmed_round_2  \\\n",
       "0  ['take', 'flavour', 'creatin', 'break', 'fast'...   \n",
       "1  ['lost', '120', 'lbsshe', 'lost', '80', 'one',...   \n",
       "2  ['fast', 'spite', 'work', 'see', '4', 'week', ...   \n",
       "3  ['daili', 'fast', 'checkin', 'type', 'fast', '...   \n",
       "4  ['90', 'day', 'intermitt', 'fast', 'work', 'hi...   \n",
       "\n",
       "                                  lemmatized_round_2  \\\n",
       "0  ['taking', 'flavoured', 'creatine', 'break', '...   \n",
       "1  ['lost', '120', 'lbsshe', 'lost', '80', 'one',...   \n",
       "2  ['fasting', 'spite', 'work', 'see', '4', 'week...   \n",
       "3  ['daily', 'fasting', 'checkin', 'type', 'fast'...   \n",
       "4  ['90', 'day', 'intermittent', 'fasting', 'work...   \n",
       "\n",
       "                                     stemmed_round_3  \\\n",
       "0  ['take', 'flavour', 'creatin', 'break', 'fast'...   \n",
       "1  ['lost', '120', 'lbsshe', 'lost', '80', 'one',...   \n",
       "2  ['fast', 'spite', 'work', 'see', '4', 'week', ...   \n",
       "3  ['daili', 'fast', 'checkin', 'type', 'fast', '...   \n",
       "4  ['90', 'day', 'intermitt', 'fast', 'work', 'hi...   \n",
       "\n",
       "                                  lemmatized_round_3  \n",
       "0  ['taking', 'flavoured', 'creatine', 'break', '...  \n",
       "1  ['lost', '120', 'lbsshe', 'lost', '80', 'one',...  \n",
       "2  ['fasting', 'spite', 'work', 'see', '4', 'week...  \n",
       "3  ['daily', 'fasting', 'checkin', 'type', 'fast'...  \n",
       "4  ['90', 'day', 'intermittent', 'fasting', 'work...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data saved in previous notebook (Part 2)\n",
    "reddit = pd.read_csv('reddit_cleaned_final.csv')\n",
    "\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9991a",
   "metadata": {},
   "source": [
    "> <font size = 3 color = \"crimson\"> Again, I will not run this as I know I will receive an error due to the changed file structure of your final directory. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a293643",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "| Column                             | Datatype  | Explanation                                           |\n",
    "| ---------------------------------- | --------- | ----------------------------------------------------- |\n",
    "| **title**                          | object    | Title of the Reddit post                              |\n",
    "| **post_text**                      | object    | Text content of the Reddit post                       |\n",
    "| **id**                             | object    | Unique identifier for the post                        |\n",
    "| **score**                          | int64     | Score or upvotes of the post                          |\n",
    "| **total_comments**                 | int64     | Total number of comments on the post                  |\n",
    "| **post_url**                       | object    | URL of the post                                       |\n",
    "| **subreddit**                      | object    | Subreddit where the post was made                     |\n",
    "| **post_type**                      | object    | Type or format of the post                            |\n",
    "| **time_uploaded**                  | object    | Timestamp when the post was uploaded                  |\n",
    "| **title_&_text**                   | object    | Title and text content with punctuations removed      |\n",
    "| **title_text_stemmed**             | object    | Title and text content after stemming                 |\n",
    "| **title_text_lemmatized**          | object    | Title and text content after lemmatization            |\n",
    "| **stemmed_round_1**                | object    | Stemmed title and text after 1st round of feature engineering|\n",
    "| **lemmatized_round_1**             | object    | Lemmatized title and text after 1st round of feature engineering|\n",
    "| **stemmed_round_2**                | object    | Stemmed title and text after 2nd round of feature engineering|\n",
    "| **lemmatized_round_2**             | object    | Lemmatized title and text after 2nd round of feature engineering|\n",
    "| **stemmed_round_3**                | object    | Stemmed title and text after 3rd round of feature engineering|\n",
    "| **lemmatized_round_3**             | object    | Lemmatized title and text after 3rd round of feature engineering|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c82b41",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Pre-processing\n",
    "---\n",
    "The pre-processing steps include:\n",
    "1. Binarizing the two subreddit to be run in the models\n",
    "2. Train-test split\n",
    "### 2.1 Binarizing The 2 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1874af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "3955    1\n",
       "3956    1\n",
       "3957    1\n",
       "3958    1\n",
       "3959    1\n",
       "Name: subreddit_binarized, Length: 3960, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarize 'subreddit' for modelling\n",
    "## 'intermittentfasting' = 0\n",
    "## 'AnorexiaNervosa' = 1\n",
    "\n",
    "reddit['subreddit_binarized'] = reddit['subreddit'].map({'intermittentfasting': 0, 'AnorexiaNervosa': 1})\n",
    "\n",
    "reddit['subreddit_binarized']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896603dd",
   "metadata": {},
   "source": [
    "**Note:** 3 sets of features are listed to check if the addition of common stopwords/unmeaningful words in each round helps to improve our model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26391628",
   "metadata": {},
   "source": [
    "> <font size = 3 color = \"crimson\"> This sequence is somewhat unnatural for reading purposes. One would expect these initial attempts to be part of the cleaning/EDA. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98acdd",
   "metadata": {},
   "source": [
    "### 2.2 Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e36a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble features (x) and target (y)\n",
    "\n",
    "X_1st_cleaning = reddit['stemmed_round_1'].tolist() # Features obtained from 1st round of cleaning\n",
    "X_2nd_cleaning = reddit['stemmed_round_2'].tolist() # Features obtained from 2nd round of cleaning\n",
    "X_final = reddit['stemmed_round_3'].tolist() # Final set of features to be used in modelling\n",
    "y = reddit['subreddit_binarized'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13163e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "\n",
    "# 1st round of cleaning\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_1st_cleaning, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2nd round of cleaning\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_2nd_cleaning, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3rd round of cleaning\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_final, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5ea6f",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Modelling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1386344",
   "metadata": {},
   "source": [
    "**Vectorizers used:** <br>\n",
    "As we need a vectorizer to convert text to numeric form for analysis, we have run each machine learning models with the following 3 vectorization methods:\n",
    "\n",
    "* **CountVectorizer** (aka N-gram (1,1)) - creates a document-term matrix where the entry of each cell will be a count of the number of times that word occurred in that document.\n",
    "* **N-gram** - is used to look for groups of adjacent words instead of just looking for single terms. N-gram (2,2) is what we use to find bigrams.\n",
    "* **TF-IDF** - is basically a count vectorizer that includes some consideration for the length of the document, and also how common the word is across other text messages\n",
    "\n",
    "### 3.1 Baseline model: Logistic Regression with Count Vectorizer\n",
    "\n",
    "To achieve the optimal model score, we have gone through:\n",
    "1. Feature Engineering\n",
    "2. Comparing Against Other Models\n",
    "\n",
    "### 3.1.1 Feature Engineering\n",
    "3 rounds of refining feature selection was carried out by adding more stopwords each time. Using the GridSearchCV function below, the baseline model will be trained using the optimal hyperparameters across 3 different sets of features. The set of features that yielded the highest model score was chosen to be run in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbd8f4",
   "metadata": {},
   "source": [
    "**GridSearchCV**\n",
    "\n",
    "To ensure our models are optimised, we will find the best parameters of each model using GridSearchCV and run the models with the optimal hyperparameters. We will first create a function to find the optimal hyperparameters and best score before running it through the 3 sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9c057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a GridSearchCV function to find the optimized model scores \n",
    "\n",
    "def grid_search(X_train, y_train):\n",
    "    \n",
    "    # Instantiate CountVectorizer\n",
    "    cv = CountVectorizer()\n",
    "    X_train_cv = cv.fit_transform(X_train)\n",
    "\n",
    "    # Apply SMOTE to the train data \n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_cv, y_train)\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],  \n",
    "        'penalty': ['l1', 'l2'],         \n",
    "        'solver': ['liblinear'],\n",
    "    }\n",
    "\n",
    "    # Instantiate a Logistic Regression model\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    # Instantiate GridSearchCV\n",
    "    gs = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit GridSearchCV to data\n",
    "    gs.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Get the best hyperparameters and best score\n",
    "    best_params = gs.best_params_\n",
    "    best_score = gs.best_score_\n",
    "    \n",
    "    return best_params, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e382e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Round</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.920561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Round</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.923988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd Round</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.923988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Round                                    Best Parameters  Best Score\n",
       "0  1st Round  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...    0.920561\n",
       "1  2nd Round  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...    0.923988\n",
       "2  3rd Round  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...    0.923988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the grid_search function to the 3 sets of data \n",
    "# Get the optimized model score after each round of cleaning\n",
    "\n",
    "# Create an empty list and store the results for each round\n",
    "results = []\n",
    "\n",
    "best_params_1st, best_score_1st = grid_search(X1_train, y1_train)\n",
    "results.append({'Round': '1st Round', 'Best Parameters': best_params_1st, 'Best Score': best_score_1st})\n",
    "\n",
    "best_params_2nd, best_score_2nd = grid_search(X2_train, y2_train)\n",
    "results.append({'Round': '2nd Round', 'Best Parameters': best_params_2nd, 'Best Score': best_score_2nd})\n",
    "\n",
    "best_params_3rd, best_score_3rd = grid_search(X2_train, y2_train)\n",
    "results.append({'Round': '3rd Round', 'Best Parameters': best_params_3rd, 'Best Score': best_score_3rd})\n",
    "\n",
    "# Convert the list of dictionaries to a data frame\n",
    "clean_progress = pd.concat([pd.DataFrame([r]) for r in results], ignore_index=True)\n",
    "\n",
    "clean_progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216c316",
   "metadata": {},
   "source": [
    "> <font size = 3 color = \"crimson\"> Perhaps rounding the numbers to 3 dp would help with clarity. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c305410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Round</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.920561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Round</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.923988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd Round</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.923988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Round                                    Best Parameters  Best Score\n",
       "0  1st Round  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...    0.920561\n",
       "1  2nd Round  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...    0.923988\n",
       "2  3rd Round  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...    0.923988"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chart to visualise model score's progress after rounds of cleaning\n",
    "\n",
    "clean_progress_graph = clean_progress[['Round', 'Best Score']]\n",
    "ax = clean_progress_graph.plot(kind='bar', figsize=(5,2))\n",
    "plt.title('Best Model Score for Each Round of Cleaning', fontsize=12)\n",
    "plt.xlabel('Round of Cleaning', fontsize=10)\n",
    "plt.ylim(0.919, 0.925)\n",
    "new_labels = ['1st', '2nd', '3rd']\n",
    "ax.set_xticklabels(new_labels)\n",
    "\n",
    "plt.show()\n",
    "clean_progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3daac26",
   "metadata": {},
   "source": [
    "**Analysis:** \n",
    "* The baseline model, Logistic Regression with Count Vectorizer, has an oustanding performance as it consistently achieved scores higher than 0.9 (an industry benchmark). \n",
    "* Out of the 3 sets of features, the 2nd set which yielded the highest score would be used in the final modelling.\n",
    "\n",
    "**Note:** The list of custom stopwords added in the 2nd set include:<br>\n",
    "['tri', 'right', 'year', 'around', 'cant', 'start', 'alway', 'end', 'hope', 'thank', 'didnt', 'gain', 'could', 'ago', 'without', 'stop', 'work', 'post', 'life', 'get', 'long', 'use', 'love', 'normal', 'say', 'week', 'past', 'comment', 'thing', 'lose', 'everyon', 'look', 'sure', 'thought', 'littl', 'peopl', 'never', 'meal', 'els', 'find', 'time', 'come', 'went', 'make', 'anyth', 'pretti', 'felt', 'almost', 'period', 'ill', 'hard', 'advic', 'notic', 'two', 'want', 'made', 'id', 'healthi', 'actual']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e2d6f",
   "metadata": {},
   "source": [
    "## 3.1.2 Comparing Against Other Models\n",
    "\n",
    "In this section, we compared our baseline model with other models to find the model with the best score.\n",
    "\n",
    "We have evaluated **9 models** in total and they were:\n",
    "\n",
    "    1. Logistic Regression with CountVectorizer (Baseline model)\n",
    "    2. Multinomial Naive Bayes with CountVectorizer \n",
    "    3. XGBoost Classifier with CountVectorizer\n",
    "    4. Logistic Regression with N-gram (2,2)\n",
    "    5. Multinomial Naive Bayes with N-gram (2,2)\n",
    "    6. XGBoost Classifier with N-gram (2,2)\n",
    "    7. Logistic Regression with TF-IDF\n",
    "    8. Multinomial Naive Bayes with TF-IDF \n",
    "    9. XGBoost Classifier with TF-IDF\n",
    "    \n",
    "**Note:**\n",
    "* **Logistic Regression model**: A statistical model used for binary classification, predicting one of two possible outcomes based on input features.\n",
    "* **Multinomial Naive Bayes model**: A probabilistic classification model often used for text classification, which assumes that features are conditionally independent and predicts multiple discrete classes.\n",
    "* **XGBoost model**: An ensemble machine learning model that boosts the performance of decision trees, often used for regression and classification tasks, known for its efficiency and accuracy.\n",
    "    \n",
    "**Model Performance Criteria:** <br>\n",
    "The models' performance would be illustrated by the following metrics after applying GridSearchCV:\n",
    "   * Accuracy (train data)\n",
    "   * Accuracy (test data)\n",
    "   * Precision (test data)\n",
    "   * Recall (test data)\n",
    "   * F1 (test data)\n",
    "   * ROC (test data)\n",
    "\n",
    "We evaluated their performance **mainly based on the accuracy (test) scores**, whilst also checking against the other metrics to for greater reliability. Finally, we also compared the execution time to ensure that performance was not improved at the expense of longer execution time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd99957",
   "metadata": {},
   "source": [
    "### 3.1.2.1 Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e3854f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.964486</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.939058</td>\n",
       "      <td>0.899204</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.923096</td>\n",
       "      <td>10.328054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                                      \n",
       "Logistic Regression  Count Vectorizer          0.964486         0.924242   \n",
       "\n",
       "                     Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                                         \n",
       "Logistic Regression          0.939058       0.899204   0.918699    0.923096   \n",
       "\n",
       "                     Execution Time (ms)  \n",
       "Model                                     \n",
       "Logistic Regression            10.328054  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate CountVectorizer \n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X2_train)\n",
    "X_test_cv = cv.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_cv, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "lr = LogisticRegression(C=1, penalty='l1', solver='liblinear') #based on the hyperparameters above\n",
    "            \n",
    "# Fit the model\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both training and test data\n",
    "y_pred_train = lr.predict(X_train_resampled)\n",
    "y_pred_test = lr.predict(X_test_cv)\n",
    "            \n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "lr_cv = pd.DataFrame({'Model': ['Logistic Regression'], \n",
    "                      'Vectorizer': ['Count Vectorizer'],\n",
    "                      'Accuracy (Train)': [accuracy_train],\n",
    "                      'Accuracy (Test)': [accuracy_test],\n",
    "                      'Precision (Test)': [precision_test],\n",
    "                      'Recall (Test)': [recall_test],\n",
    "                      'F1 (Test)': [f1_test],\n",
    "                      'ROC (Test)': [roc_test], \n",
    "                      'Execution Time (ms)': [exec_time]})\n",
    "lr_cv.set_index('Model', inplace=True)\n",
    "\n",
    "lr_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb41ef",
   "metadata": {},
   "source": [
    "### 3.1.2.2 Multinomial NB with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9f0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.5, 'fit_prior': True}\n",
      "Best score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_cv, y2_train)\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "multi = MultinomialNB()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_multi = GridSearchCV(estimator=multi, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_multi.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_multi_cv = gs_multi.best_params_\n",
    "best_score_multi_cv = gs_multi.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_multi_cv}')\n",
    "print(f'Best score: {best_score_multi_cv:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9313063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.961994</td>\n",
       "      <td>0.945707</td>\n",
       "      <td>0.948925</td>\n",
       "      <td>0.93634</td>\n",
       "      <td>0.94259</td>\n",
       "      <td>0.945278</td>\n",
       "      <td>0.955105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                                 \n",
       "Multinomial NB  Count Vectorizer          0.961994         0.945707   \n",
       "\n",
       "                Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                                    \n",
       "Multinomial NB          0.948925        0.93634    0.94259    0.945278   \n",
       "\n",
       "                Execution Time (ms)  \n",
       "Model                                \n",
       "Multinomial NB             0.955105  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate CountVectorizer \n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X2_train)\n",
    "X_test_cv = cv.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_cv, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "multi = MultinomialNB()\n",
    "multi.set_params(**best_params_multi_cv)\n",
    "            \n",
    "# Fit the model\n",
    "multi.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both training and test data\n",
    "y_pred_train = multi.predict(X_train_resampled)\n",
    "y_pred_test = multi.predict(X_test_cv)\n",
    "            \n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "multi_cv = pd.DataFrame({'Model': ['Multinomial NB'], \n",
    "                         'Vectorizer': ['Count Vectorizer'],\n",
    "                         'Accuracy (Train)': [accuracy_train],\n",
    "                         'Accuracy (Test)': [accuracy_test],\n",
    "                         'Precision (Test)': [precision_test],\n",
    "                         'Recall (Test)': [recall_test],\n",
    "                         'F1 (Test)': [f1_test],\n",
    "                         'ROC (Test)': [roc_test],\n",
    "                         'Execution Time (ms)': [exec_time]})\n",
    "\n",
    "multi_cv.set_index('Model', inplace=True)\n",
    "\n",
    "multi_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e4292",
   "metadata": {},
   "source": [
    "### 3.1.2.3 XGBoost with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1add4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Best score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_cv, y2_train)\n",
    "\n",
    "# Instantiate an XGBoost model\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_xgb.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_xgb_cv = gs_xgb.best_params_\n",
    "best_score_xgb_cv = gs_xgb.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_xgb_cv}')\n",
    "print(f'Best score: {best_score_xgb_cv:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65152d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.972897</td>\n",
       "      <td>0.938131</td>\n",
       "      <td>0.92268</td>\n",
       "      <td>0.949602</td>\n",
       "      <td>0.935948</td>\n",
       "      <td>0.938656</td>\n",
       "      <td>165.045023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                          \n",
       "XGBoost  Count Vectorizer          0.972897         0.938131   \n",
       "\n",
       "         Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                             \n",
       "XGBoost           0.92268       0.949602   0.935948    0.938656   \n",
       "\n",
       "         Execution Time (ms)  \n",
       "Model                         \n",
       "XGBoost           165.045023  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate CountVectorizer \n",
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(X2_train)\n",
    "X_test_cv = cv.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_cv, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate an XGBoost model\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "            \n",
    "# Fit the model\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both training and test data\n",
    "y_pred_train = xgb.predict(X_train_resampled)\n",
    "y_pred_test = xgb.predict(X_test_cv)\n",
    "            \n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "xgb_cv = pd.DataFrame({'Model': ['XGBoost'], \n",
    "                      'Vectorizer': ['Count Vectorizer'],\n",
    "                      'Accuracy (Train)': [accuracy_train],\n",
    "                      'Accuracy (Test)': [accuracy_test],\n",
    "                      'Precision (Test)': [precision_test],\n",
    "                      'Recall (Test)': [recall_test],\n",
    "                      'F1 (Test)': [f1_test],\n",
    "                      'ROC (Test)': [roc_test],\n",
    "                      'Execution Time (ms)': [exec_time]})\n",
    "xgb_cv.set_index('Model', inplace=True)\n",
    "\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ed3b0",
   "metadata": {},
   "source": [
    "### 3.1.2.4 Logistic Regression with N-gram (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ab099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "ngram = CountVectorizer(ngram_range=(2,2))\n",
    "X_train_ngram = cv.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_ngram, y2_train)\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "                           'penalty': ['l1', 'l2'],   \n",
    "                           'solver': ['liblinear']\n",
    "                          }\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_lr = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_lr.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_lr_ngram = gs_lr.best_params_\n",
    "best_score_lr_ngram = gs_lr.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_lr_ngram}')\n",
    "print(f'Best score: {best_score_lr_ngram:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d75f4743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>N-gram (2,2)</td>\n",
       "      <td>0.936449</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.925094</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.767081</td>\n",
       "      <td>0.80349</td>\n",
       "      <td>49.114227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                                  \n",
       "Logistic Regression  N-gram (2,2)          0.936449         0.810606   \n",
       "\n",
       "                     Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                                         \n",
       "Logistic Regression          0.925094       0.655172   0.767081     0.80349   \n",
       "\n",
       "                     Execution Time (ms)  \n",
       "Model                                     \n",
       "Logistic Regression            49.114227  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate CountVectorizer \n",
    "ngram = CountVectorizer(ngram_range=(2,2))\n",
    "X_train_ngram = ngram.fit_transform(X2_train)\n",
    "X_test_ngram = ngram.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_ngram, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "lr = LogisticRegression()\n",
    "lr.set_params(**best_params_lr_ngram)\n",
    "            \n",
    "# Fit the model\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both training and test data\n",
    "y_pred_train = lr.predict(X_train_resampled)\n",
    "y_pred_test = lr.predict(X_test_ngram)\n",
    "            \n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "lr_ngram = pd.DataFrame({'Model': ['Logistic Regression'], \n",
    "                         'Vectorizer': ['N-gram (2,2)'],\n",
    "                         'Accuracy (Train)': [accuracy_train],\n",
    "                         'Accuracy (Test)': [accuracy_test],\n",
    "                         'Precision (Test)': [precision_test],\n",
    "                         'Recall (Test)': [recall_test],\n",
    "                         'F1 (Test)': [f1_test],\n",
    "                         'ROC (Test)': [roc_test],\n",
    "                         'Execution Time (ms)': [exec_time]})\n",
    "\n",
    "lr_ngram.set_index('Model', inplace=True)\n",
    "\n",
    "lr_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660254d3",
   "metadata": {},
   "source": [
    "### 3.1.2.5 Multinomial NB with N-gram (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7020b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.5, 'fit_prior': True}\n",
      "Best score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "ngram = CountVectorizer(ngram_range=(2,2))\n",
    "X_train_ngram = cv.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_ngram, y2_train)\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "multi = MultinomialNB()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_multi = GridSearchCV(estimator=multi, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_multi.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_multi_ngram = gs_multi.best_params_\n",
    "best_score_multi_ngram = gs_multi.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_multi_ngram}')\n",
    "print(f'Best score: {best_score_multi_ngram:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50391fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>N-gram (2,2)</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.885942</td>\n",
       "      <td>0.891856</td>\n",
       "      <td>0.897188</td>\n",
       "      <td>1.876116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                             \n",
       "Multinomial NB  N-gram (2,2)          0.981308         0.897727   \n",
       "\n",
       "                Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                                    \n",
       "Multinomial NB          0.897849       0.885942   0.891856    0.897188   \n",
       "\n",
       "                Execution Time (ms)  \n",
       "Model                                \n",
       "Multinomial NB             1.876116  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate CountVectorizer \n",
    "ngram = CountVectorizer(ngram_range=(2,2))\n",
    "X_train_ngram = ngram.fit_transform(X2_train)\n",
    "X_test_ngram = ngram.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_ngram, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "multi = MultinomialNB()\n",
    "multi.set_params(**best_params_multi_ngram)\n",
    "            \n",
    "# Fit the model\n",
    "multi.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both training and test data\n",
    "y_pred_train = multi.predict(X_train_resampled)\n",
    "y_pred_test = multi.predict(X_test_ngram)\n",
    "            \n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "multi_ngram = pd.DataFrame({'Model': ['Multinomial NB'], \n",
    "                         'Vectorizer': ['N-gram (2,2)'],\n",
    "                         'Accuracy (Train)': [accuracy_train],\n",
    "                         'Accuracy (Test)': [accuracy_test],\n",
    "                         'Precision (Test)': [precision_test],\n",
    "                         'Recall (Test)': [recall_test],\n",
    "                         'F1 (Test)': [f1_test],\n",
    "                         'ROC (Test)': [roc_test],\n",
    "                         'Execution Time (ms)': [exec_time]})\n",
    "\n",
    "multi_ngram.set_index('Model', inplace=True)\n",
    "\n",
    "multi_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c223e6",
   "metadata": {},
   "source": [
    "### 3.1.2.6 XGBoost with N-gram (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3252e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Best score: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "ngram = CountVectorizer(ngram_range=(2,2))\n",
    "X_train_xgb = cv.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_ngram, y2_train)\n",
    "\n",
    "# Instantiate an XGBoost model\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {'n_estimators': [100, 200, 300],\n",
    "              'max_depth': [3, 4, 5],\n",
    "              'learning_rate': [0.001, 0.01, 0.1]\n",
    "             }\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_xgb.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_xgb_ngram = gs_xgb.best_params_\n",
    "best_score_xgb_ngram = gs_xgb.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_xgb_ngram}')\n",
    "print(f'Best score: {best_score_xgb_ngram:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd2510d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>N-gram (2,2)</td>\n",
       "      <td>0.850779</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.636605</td>\n",
       "      <td>0.739599</td>\n",
       "      <td>0.779748</td>\n",
       "      <td>810.106993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Vectorizer  Accuracy (Train)  Accuracy (Test)  Precision (Test)  \\\n",
       "Model                                                                        \n",
       "XGBoost  N-gram (2,2)          0.850779         0.786616          0.882353   \n",
       "\n",
       "         Recall (Test)  F1 (Test)  ROC (Test)  Execution Time (ms)  \n",
       "Model                                                               \n",
       "XGBoost       0.636605   0.739599    0.779748           810.106993  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate CountVectorizer \n",
    "ngram = CountVectorizer(ngram_range=(2,2))\n",
    "X_train_ngram = ngram.fit_transform(X2_train)\n",
    "X_test_ngram = ngram.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the train data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_ngram, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate an XGBoost model\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "            \n",
    "# Fit the model\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both training and test data\n",
    "y_pred_train = xgb.predict(X_train_resampled)\n",
    "y_pred_test = xgb.predict(X_test_ngram)\n",
    "            \n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "xgb_ngram = pd.DataFrame({'Model': ['XGBoost'], \n",
    "                      'Vectorizer': ['N-gram (2,2)'],\n",
    "                      'Accuracy (Train)': [accuracy_train],\n",
    "                      'Accuracy (Test)': [accuracy_test],\n",
    "                      'Precision (Test)': [precision_test],\n",
    "                      'Recall (Test)': [recall_test],\n",
    "                      'F1 (Test)': [f1_test],\n",
    "                      'ROC (Test)': [roc_test],\n",
    "                      'Execution Time (ms)': [exec_time]})\n",
    "xgb_ngram.set_index('Model', inplace=True)\n",
    "\n",
    "xgb_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f8383",
   "metadata": {},
   "source": [
    "### 3.1.2.7 Logistic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0475b122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "X_train_tf = tf.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tf, y2_train)\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "                           'penalty': ['l1', 'l2'],   \n",
    "                           'solver': ['liblinear']\n",
    "                          }\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_lr = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_lr.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_lr_tf = gs_lr.best_params_\n",
    "best_score_lr_tf = gs_lr.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_lr_tf}')\n",
    "print(f'Best score: {best_score_lr_tf:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d2e86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.993458</td>\n",
       "      <td>0.926768</td>\n",
       "      <td>0.932249</td>\n",
       "      <td>0.912467</td>\n",
       "      <td>0.922252</td>\n",
       "      <td>0.926113</td>\n",
       "      <td>9.712934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                               \n",
       "Logistic Regression     TF-IDF          0.993458         0.926768   \n",
       "\n",
       "                     Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                                         \n",
       "Logistic Regression          0.932249       0.912467   0.922252    0.926113   \n",
       "\n",
       "                     Execution Time (ms)  \n",
       "Model                                     \n",
       "Logistic Regression             9.712934  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate Count Vectorizer \n",
    "tf = TfidfVectorizer()\n",
    "X_train_tf = tf.fit_transform(X2_train)\n",
    "X_test_tf = tf.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the train data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tf, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.set_params(**best_params_lr_tf)\n",
    "            \n",
    "# Fit the model\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both train and test data\n",
    "y_pred_train = lr.predict(X_train_resampled)\n",
    "y_pred_test = lr.predict(X_test_tf)\n",
    "\n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "lr_tfidf = pd.DataFrame({'Model': ['Logistic Regression'], \n",
    "                         'Vectorizer': ['TF-IDF'],\n",
    "                         'Accuracy (Train)': [accuracy_train],\n",
    "                         'Accuracy (Test)': [accuracy_test],\n",
    "                         'Precision (Test)': [precision_test],\n",
    "                         'Recall (Test)': [recall_test],\n",
    "                         'F1 (Test)': [f1_test],\n",
    "                         'ROC (Test)': [roc_test],\n",
    "                         'Execution Time (ms)': [exec_time]})\n",
    "\n",
    "lr_tfidf.set_index('Model', inplace=True)\n",
    "\n",
    "lr_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf9c5b",
   "metadata": {},
   "source": [
    "### 3.1.2.8 Multinomial NB with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb8836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.5, 'fit_prior': True}\n",
      "Best score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "X_train_tf = tf.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tf, y2_train)\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "multi = MultinomialNB()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0],\n",
    "              'fit_prior': [True, False]}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_multi = GridSearchCV(estimator=multi, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_multi.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_multi_tf = gs_multi.best_params_\n",
    "best_score_multi_tf = gs_multi.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_multi_tf}')\n",
    "print(f'Best score: {best_score_multi_tf:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46b31acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.964798</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.938992</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>0.929737</td>\n",
       "      <td>1.034975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                          \n",
       "Multinomial NB     TF-IDF          0.964798         0.929293   \n",
       "\n",
       "                Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                                    \n",
       "Multinomial NB          0.914729       0.938992   0.926702    0.929737   \n",
       "\n",
       "                Execution Time (ms)  \n",
       "Model                                \n",
       "Multinomial NB             1.034975  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate Count Vectorizer \n",
    "tf = TfidfVectorizer()\n",
    "X_train_tf = tf.fit_transform(X2_train)\n",
    "X_test_tf = tf.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the train data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tf, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "multi = MultinomialNB()\n",
    "multi.set_params(**best_params_multi_tf)\n",
    "            \n",
    "# Fit the model\n",
    "multi.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both train and test data\n",
    "y_pred_train = multi.predict(X_train_resampled)\n",
    "y_pred_test = multi.predict(X_test_tf)\n",
    "\n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "multi_tfidf = pd.DataFrame({'Model': ['Multinomial NB'], \n",
    "                         'Vectorizer': ['TF-IDF'],\n",
    "                         'Accuracy (Train)': [accuracy_train],\n",
    "                         'Accuracy (Test)': [accuracy_test],\n",
    "                         'Precision (Test)': [precision_test],\n",
    "                         'Recall (Test)': [recall_test],\n",
    "                         'F1 (Test)': [f1_test],\n",
    "                         'ROC (Test)': [roc_test],\n",
    "                         'Execution Time (ms)': [exec_time]})\n",
    "\n",
    "multi_tfidf.set_index('Model', inplace=True)\n",
    "\n",
    "multi_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5b44b",
   "metadata": {},
   "source": [
    "### 3.1.2.9 XGBoost with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b8b359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 300}\n",
      "Best score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Find best hyperparameters\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "X_train_tf = tf.fit_transform(X2_train)\n",
    "\n",
    "# Apply SMOTE to the train data \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tf, y2_train)\n",
    "\n",
    "# Instantiate the Multinomial NB model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {'n_estimators': [100, 200, 300],\n",
    "              'max_depth': [3, 4, 5],\n",
    "              'learning_rate': [0.001, 0.01, 0.1]\n",
    "             }\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to data\n",
    "gs_xgb.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "# Get the best hyperparameters and best score\n",
    "best_params_xgb_tf = gs_xgb.best_params_\n",
    "best_score_xgb_tf = gs_xgb.best_score_\n",
    "    \n",
    "print(f'Best hyperparameters: {best_params_xgb_tf}')\n",
    "print(f'Best score: {best_score_xgb_tf:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c15496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.978816</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.938992</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>0.929737</td>\n",
       "      <td>794.212103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Vectorizer  Accuracy (Train)  Accuracy (Test)  Precision (Test)  \\\n",
       "Model                                                                     \n",
       "XGBoost     TF-IDF          0.978816         0.929293          0.914729   \n",
       "\n",
       "         Recall (Test)  F1 (Test)  ROC (Test)  Execution Time (ms)  \n",
       "Model                                                               \n",
       "XGBoost       0.938992   0.926702    0.929737           794.212103  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find scores\n",
    "\n",
    "# Instantiate Count Vectorizer \n",
    "tf = TfidfVectorizer()\n",
    "X_train_tf = tf.fit_transform(X2_train)\n",
    "X_test_tf = tf.transform(X2_test)\n",
    "\n",
    "# Apply SMOTE to the train data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tf, y2_train)\n",
    "\n",
    "# Start of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Instantiate the XGBooster model\n",
    "xgb = XGBClassifier()\n",
    "            \n",
    "# Fit the model\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Find execution time\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) * 1000\n",
    "            \n",
    "# Make predictions on both train and test data\n",
    "y_pred_train = xgb.predict(X_train_resampled)\n",
    "y_pred_test = xgb.predict(X_test_tf)\n",
    "\n",
    "# Accuracy (train)\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# Accuracy (test)\n",
    "accuracy_test = accuracy_score(y2_test, y_pred_test)\n",
    "            \n",
    "# Precision (test)\n",
    "precision_test = precision_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# Recall (test)\n",
    "recall_test = recall_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# F1 (test)\n",
    "f1_test = f1_score(y2_test, y_pred_test, average='binary')\n",
    "            \n",
    "# ROC (test)\n",
    "roc_test = roc_auc_score(y2_test, y_pred_test)\n",
    "\n",
    "xgb_tfidf = pd.DataFrame({'Model': ['XGBoost'], \n",
    "                         'Vectorizer': ['TF-IDF'],\n",
    "                         'Accuracy (Train)': [accuracy_train],\n",
    "                         'Accuracy (Test)': [accuracy_test],\n",
    "                         'Precision (Test)': [precision_test],\n",
    "                         'Recall (Test)': [recall_test],\n",
    "                         'F1 (Test)': [f1_test],\n",
    "                         'ROC (Test)': [roc_test],\n",
    "                         'Execution Time (ms)': [exec_time]})\n",
    "\n",
    "xgb_tfidf.set_index('Model', inplace=True)\n",
    "\n",
    "xgb_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68103860",
   "metadata": {},
   "source": [
    "### 3.1.3 Summary of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0adbd45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy (Train)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>Precision (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>ROC (Test)</th>\n",
       "      <th>Execution Time (ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>N-gram (2,2)</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>810.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>N-gram (2,2)</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>49.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>N-gram (2,2)</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>10.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>794.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>165.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial NB</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Vectorizer  Accuracy (Train)  Accuracy (Test)  \\\n",
       "Model                                                                      \n",
       "XGBoost                  N-gram (2,2)              0.85             0.79   \n",
       "Logistic Regression      N-gram (2,2)              0.94             0.81   \n",
       "Multinomial NB           N-gram (2,2)              0.98             0.90   \n",
       "Logistic Regression  Count Vectorizer              0.96             0.92   \n",
       "Logistic Regression            TF-IDF              0.99             0.93   \n",
       "Multinomial NB                 TF-IDF              0.96             0.93   \n",
       "XGBoost                        TF-IDF              0.98             0.93   \n",
       "XGBoost              Count Vectorizer              0.97             0.94   \n",
       "Multinomial NB       Count Vectorizer              0.96             0.95   \n",
       "\n",
       "                     Precision (Test)  Recall (Test)  F1 (Test)  ROC (Test)  \\\n",
       "Model                                                                         \n",
       "XGBoost                          0.88           0.64       0.74        0.78   \n",
       "Logistic Regression              0.93           0.66       0.77        0.80   \n",
       "Multinomial NB                   0.90           0.89       0.89        0.90   \n",
       "Logistic Regression              0.94           0.90       0.92        0.92   \n",
       "Logistic Regression              0.93           0.91       0.92        0.93   \n",
       "Multinomial NB                   0.91           0.94       0.93        0.93   \n",
       "XGBoost                          0.91           0.94       0.93        0.93   \n",
       "XGBoost                          0.92           0.95       0.94        0.94   \n",
       "Multinomial NB                   0.95           0.94       0.94        0.95   \n",
       "\n",
       "                     Execution Time (ms)  \n",
       "Model                                     \n",
       "XGBoost                           810.11  \n",
       "Logistic Regression                49.11  \n",
       "Multinomial NB                      1.88  \n",
       "Logistic Regression                10.33  \n",
       "Logistic Regression                 9.71  \n",
       "Multinomial NB                      1.03  \n",
       "XGBoost                           794.21  \n",
       "XGBoost                           165.05  \n",
       "Multinomial NB                      0.96  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_results = pd.concat([lr_cv, multi_cv, xgb_cv, lr_ngram, multi_ngram, xgb_ngram, lr_tfidf, multi_tfidf, xgb_tfidf]).round(2)\n",
    "overall_results.sort_values(by='Accuracy (Test)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53771935",
   "metadata": {},
   "source": [
    "**Multinomial NB (with Count Vectorizer)** is our final chosen model as it has the **highest mean accuracy**, **consistently high scores across all metrics (0.90<)**, and **fastest execution time**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b08ac",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Conclusion\n",
    "---\n",
    "### 4.1 Summary\n",
    "* The 2nd set of features were chosen given its best model score compared with the other two rounds of feature engineering.\n",
    "* All the XGBoost models had very long execution times due to their nature of sequential prediction of decision trees. This model should not be considered in this use case in the future to prevent inefficiency.\n",
    "* Despite a stellar performance, our baseline model, Logistic Regression with Count Vectorizer, was outperformed by Multinomial NB with Count Vectorizer in all test scores. This likely attributed to how Multinomial NB is:\n",
    "    - well-suited for **text classification tasks**\n",
    "    - makes a **\"naive\" assumption that features (i.e. words/tokens) are conditionally independent** given the class label, especially if there are strong keyword associations between the 2 classes\n",
    "    - designed for **categorical data**, which can be a better fit when dealing with text data where each word or token can be treated as a category\n",
    "\n",
    "### 4.2 Recommendations\n",
    "* As people who practise intermittent fasting might end up binging after breaking fast, it is recommended that the application explores the other spectrum of eating disorder as well.\n",
    "* With little information on the demographics of the intermittent fasting and anorexia communities, our application can help to explore these parameters based on the user profile information and develop more targeted solutions to address anorexia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f311941",
   "metadata": {},
   "source": [
    "---\n",
    "**Back to first:** [Part 1 - Web Scraping](Part%201%20-%20Web%20Scraping.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
