{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91e02de",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid thistle; padding: 5px 20px 10px 20px;\">\n",
    "    <h2><font color = \"77658f\" style=\";\">Feedback</font></h2><br>\n",
    "    <font color = \"77658f\"> • Problem Statement: Problem Statement is well crafted and it is clear why it is important to address. Would be improved even further if there was also some element of urgency. <br> • Data Collection: Data collection was performed effectively with code wrapped in a function. However, raw csvs were not included for evaluation. <br>• Data Cleaning and EDA: Cleaning was possibly over-thorough, with removal of words that seem relevant and meaningful. More visualisations should have been done to illustrate key insights. I found that the cleaning and EDA should have been in one single workbook with more markdowns to explain the reasoning for removal of stopwords. <br>• Preprocessing and Modelling: Generally all right, although it would have been good to make use of pipelines. <br>• Evaluation and Conceptual Understanding: Explanations are okay but could be a bit more thorough, particularly with explaining unusual words that appeared in top n-grams. <br> • Conclusion and recommendations: The conclusions and recommendations could have been elaborated on further but generally answered the problem statement. <br> • Organization: The organisation is confusing on a few levels. Firstly from a file organisation perspective, several files that are referenced were not included in the github link, and furthermore the one file that was was is not referenced correctly (both the name and address are wrong). Secondly, the logical sequence of the notebooks is broken up and requires the reader to either read earlier books with zero context or to read back and forth between the cleaning, EDA, and modelling books in order to get a full understanding for how and why the stop words were extended. <br> • Visualizations: Visualizations are generally fine but not necessarily descriptive. Most notably the venn diagrams don't seem to have much of a markdown explaining the value in seeing the number of common vs uncommon words in the top 100. <br> • Python Syntax and Control Flow: Coding syntax is generally fine, although conventionally one would expect to see the use of pipelines in such a project. <br> Presentation: A great improvement from project 2, however please note that your problem statement slide should show the problem statement.  <br><br>\n",
    "        • Problem Statement: <b>3</b> <br>\n",
    "        • Data Collection: <b>3</b> <br>\n",
    "        • Data Cleaning and EDA: <b>2</b> <br>\n",
    "        • Preprocessing and Modeling: <b>2</b><br>\n",
    "        • Evaluation and Conceptual Understanding: <b>3</b><br>\n",
    "        • Conclusion and Recommendation: <b>2</b><br>\n",
    "        • Organization: <b>1</b><br>\n",
    "        • Visualizations: <b>2</b><br>\n",
    "        • Python Syntax and Control Flow: <b>2</b><br>\n",
    "        • Presentation: <b>2</b><br>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c7509",
   "metadata": {},
   "source": [
    "<img src='http://imgur.com/1ZcRyrc.png' style='float: left; margin: 20px; height: 55px'>\n",
    "\n",
    "# Project 3: Reddit Web Scraping\n",
    "\n",
    "## Part 1 - Web Scraping\n",
    "\n",
    "---\n",
    "## Contents\n",
    "---\n",
    "\n",
    "### [Part 1 - Web Scraping](Part%201%20-%20Web%20Scraping.ipynb)\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Web Scraping Using PRAW](#2.-Web-Scraping-Using-PRAW)\n",
    "\n",
    "### [Part 2 - Data Cleaning](Part%202%20-%20Data%20Cleaning.ipynb)\n",
    "1. Import\n",
    "2. Cleaning - Data Frame and Text\n",
    "\n",
    "### [Part 3 - Exploratory Data Analysis (EDA)](Part%203%20-%20Exploratory%20Data%20Analysis%20(EDA).ipynb)\n",
    "1. Import\n",
    "2. Exploratory Data Analysis - Trends\n",
    "3. Exploratory Data Analysis - Unigrams \n",
    "4. Exploratory Data Analysis - Bigrams\n",
    "5. Exploratory Data Analysis - Trigrams \n",
    "\n",
    "### [Part 4 - Pre-processing & Modelling](Part%204%20-%20Pre-processing%20&%20Modelling.ipynb)\n",
    "1. Import\n",
    "2. Pre-processing - Binarizing The 2 Classes, Train-test Split\n",
    "3. Modelling - Feature Engineering, Comparing Against Other Models\n",
    "4. Conclusion - Summary, Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9991a",
   "metadata": {},
   "source": [
    "> <font size = 3 color = \"crimson\"> Good clear contents page. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba01915",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction \n",
    "---\n",
    "\n",
    "### 1.1 Background\n",
    "\n",
    "The trends in intermittent fasting and anorexia have raised concerns due to their potential detrimental effects on physical and mental health. \n",
    "\n",
    "Intermittent fasting is a dietary approach that involves cycling between periods of eating and fasting. This has been a trend among Singaporeans who are trying to lose weight (SingHealth, 2021). However, when practiced without proper guidance or medical supervision, it can lead to nutrient deficiencies, muscle loss, and an unhealthy fixation on food and body image. On the other hand, anorexia nervosa, an eating disorder characterized by extreme restriction of food intake, can have severe consequences, including malnutrition, organ damage, and even death (SGH, 2019). Click on the following links to find out more:\n",
    "\n",
    "* <a href='https://www.healthxchange.sg/food-nutrition/weight-management/intermittent-fasting-how-to-do-safely'> Intermittent fasting </a>\n",
    "* <a href='https://scc.sg/e/anorexia-nervosa/'> Anorexia nervosa </a>\n",
    "\n",
    "The troubling connection lies in the blurred lines between health-conscious fasting and disordered eating behaviors. Promoting unrealistic body ideals and glorifying extreme fasting methods can inadvertently contribute to the development of anorexic tendencies among vulnerable individuals. It is crucial to prioritize balanced, sustainable nutrition and seek professional guidance when considering any dietary changes to ensure both physical and mental well-being.\n",
    "\n",
    "### 1.2 Problem Statement\n",
    "\n",
    "39 SIR, one of the leading healthcare groups in Singapore, seeks to distinguish whether individuals practising intermittent fasting may be exhibiting signs of anorexia nervosa. Our objective is to offer appropriate guidance to ensure that their fasting practices promote overall health or to provide resources on how to seek assistance if they show symptoms of anorexia.\n",
    "\n",
    "<img src='internet_use_sg.png' width='650' height='350'>\n",
    "<center> (Source: Meltwater, 2023) </center>\n",
    "\n",
    "In a country where 96.9% of the population are active internet users, 39 SIR is committed to connecting with Singaporeans through digital channels. Our dedicated Data Science team have gone through rigorous research to develop a seamless application that helps individuals and healthcare facilities effectively identify people who may be at risk of anorexia nervosa. This application is designed to facilitate timely interventions and support for those requiring assistance.\n",
    "\n",
    "This application was developed through the following steps:\n",
    "\n",
    "1. Webscraping of subreddits\n",
    "2. Data cleaning\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Pre-processing and modelling\n",
    "5. Application development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2152b",
   "metadata": {},
   "source": [
    "> <font size = 3 color = \"crimson\"> Would be good in future to show proof that intermittent fasting is indeed becoming more popular, but overall it's a reasonably good problem statement. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ac990",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Web Scraping Using PRAW\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179aaa2",
   "metadata": {},
   "source": [
    "### 2.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09c55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import praw\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import itertools\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.util import bigrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbe64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Reddit API client\n",
    "redditscrapper = praw.Reddit(\n",
    "    client_id='mTKAc7piwaoiD3fvkhY7qA',\n",
    "    client_secret='GdT29i_cBYDTJwb0eExYEh6prVceGg',\n",
    "    user_agent='(REDACTED NAME HERE)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff99209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of subreddit names to scrape\n",
    "subreddit_names = ['intermittentfasting', 'AnorexiaNervosa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d8f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The subreddit at https://www.reddit.com/r/intermittentfasting is accessible.\n",
      "Success! The subreddit at https://www.reddit.com/r/AnorexiaNervosa is accessible.\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the subreddit names to test accessibility\n",
    "for subreddit_name in subreddit_names:\n",
    "    reddit_url = f'https://www.reddit.com/r/{subreddit_name}'\n",
    "    response = requests.get(reddit_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f'Success! The subreddit at {reddit_url} is accessible.')\n",
    "    else:\n",
    "        print(f'Error! The subreddit at {reddit_url} returned a status code of {response.status_code}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f190694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store post data\n",
    "posts_dict = {'Title': [],\n",
    "              'Post Text': [],\n",
    "              'ID': [],\n",
    "              'Score': [],\n",
    "              'Total Comments': [],\n",
    "              'Post URL': [],\n",
    "              'Subreddit': [],\n",
    "              'Post Type': [],\n",
    "              'Time Uploaded': []\n",
    "             }\n",
    "\n",
    "# Set to keep track of collected post IDs\n",
    "post_ids = set()\n",
    "\n",
    "# Define a dictionary to map post types to fetch functions\n",
    "post_type_mapping = {'new': 'new',\n",
    "                     'hot': 'hot',\n",
    "                     'top': 'top',\n",
    "                     'rising': 'rising'\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52211549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-deleted/non-removed posts collected: 3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>Time uploaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does taking flavoured creatine break a fast?</td>\n",
       "      <td>Taking one scoop, roughly 3g. It has sucralose...</td>\n",
       "      <td>16shh83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/intermittentfasting/c...</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>2023-09-26 07:57:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I lost 120 lbs.......she lost 80. One meal a d...</td>\n",
       "      <td></td>\n",
       "      <td>16shbmz</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.redd.it/cft42u8lso151.jpg</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>2023-09-26 07:46:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does fasting out of spite work?</td>\n",
       "      <td>We’ll see in 4 weeks when I go to a wedding wh...</td>\n",
       "      <td>16sfrlc</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/intermittentfasting/c...</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>2023-09-26 06:10:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daily Fasting Check-in!</td>\n",
       "      <td>* **Type** of fast (water, juice, smoking, etc...</td>\n",
       "      <td>16sfl07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/intermittentfasting/c...</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>2023-09-26 06:00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90 Days of Intermittent Fasting - IT WORKS!</td>\n",
       "      <td>Hi Everyone, \\n\\nToday was the 90th day of my ...</td>\n",
       "      <td>16sdl2e</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.reddit.com/r/intermittentfasting/c...</td>\n",
       "      <td>intermittentfasting</td>\n",
       "      <td>new</td>\n",
       "      <td>2023-09-26 04:10:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0       Does taking flavoured creatine break a fast?   \n",
       "1  I lost 120 lbs.......she lost 80. One meal a d...   \n",
       "2                    Does fasting out of spite work?   \n",
       "3                            Daily Fasting Check-in!   \n",
       "4        90 Days of Intermittent Fasting - IT WORKS!   \n",
       "\n",
       "                                           Post Text       ID  Score  \\\n",
       "0  Taking one scoop, roughly 3g. It has sucralose...  16shh83      1   \n",
       "1                                                     16shbmz      6   \n",
       "2  We’ll see in 4 weeks when I go to a wedding wh...  16sfrlc      0   \n",
       "3  * **Type** of fast (water, juice, smoking, etc...  16sfl07      1   \n",
       "4  Hi Everyone, \\n\\nToday was the 90th day of my ...  16sdl2e     17   \n",
       "\n",
       "   Total Comments                                           Post URL  \\\n",
       "0               0  https://www.reddit.com/r/intermittentfasting/c...   \n",
       "1               1                https://i.redd.it/cft42u8lso151.jpg   \n",
       "2               2  https://www.reddit.com/r/intermittentfasting/c...   \n",
       "3               0  https://www.reddit.com/r/intermittentfasting/c...   \n",
       "4               8  https://www.reddit.com/r/intermittentfasting/c...   \n",
       "\n",
       "             Subreddit Post Type       Time uploaded  \n",
       "0  intermittentfasting       new 2023-09-26 07:57:13  \n",
       "1  intermittentfasting       new 2023-09-26 07:46:54  \n",
       "2  intermittentfasting       new 2023-09-26 06:10:27  \n",
       "3  intermittentfasting       new 2023-09-26 06:00:31  \n",
       "4  intermittentfasting       new 2023-09-26 04:10:24  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through the subreddit names and post types to fetch and collect posts\n",
    "for subreddit_name in subreddit_names:\n",
    "    subreddit = redditscrapper.subreddit(subreddit_name)\n",
    "    \n",
    "    # Fetch posts using the mapping\n",
    "    for post_type, fetch_function in post_type_mapping.items():\n",
    "        posts = getattr(subreddit, fetch_function)(limit=1000000)\n",
    "        \n",
    "        for post in posts:\n",
    "            \n",
    "            if post.id not in post_ids:\n",
    "                post_ids.add(post.id)\n",
    "                \n",
    "                # Only append posts that are not deleted nor removed\n",
    "                if post.selftext != '[deleted]' and post.selftext != '[removed]':\n",
    "                    posts_dict['Title'].append(post.title)\n",
    "                    posts_dict['Post Text'].append(post.selftext)\n",
    "                    posts_dict['ID'].append(post.id)\n",
    "                    posts_dict['Score'].append(post.score)\n",
    "                    posts_dict['Total Comments'].append(post.num_comments)\n",
    "                    posts_dict['Post URL'].append(post.url)\n",
    "                    posts_dict['Subreddit'].append(subreddit_name)\n",
    "                    posts_dict['Post Type'].append(post_type)\n",
    "                    time_uploaded = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    posts_dict['Time uploaded'].append(time_uploaded)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "all_posts = pd.DataFrame(posts_dict)\n",
    "\n",
    "# Print a summary of the collected data\n",
    "print(f'Total number of non-deleted/non-removed posts collected: {len(all_posts)}')\n",
    "all_posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a8dd9",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "| Column                             | Datatype  | Explanation                                           |\n",
    "| ---------------------------------- | --------- | ----------------------------------------------------- |\n",
    "| **title**                          | object    | Title of the Reddit post                              |\n",
    "| **post_text**                      | object    | Text content of the Reddit post                       |\n",
    "| **id**                             | object    | Unique identifier for the post                        |\n",
    "| **score**                          | int64     | Score or upvotes of the post                          |\n",
    "| **total_comments**                 | int64     | Total number of comments on the post                  |\n",
    "| **post_url**                       | object    | URL of the post                                       |\n",
    "| **subreddit**                      | object    | Subreddit where the post was made                     |\n",
    "| **post_type**                      | object    | Type or format of the post                            |\n",
    "| **time_uploaded**                  | object    | Timestamp when the post was uploaded                  |\n",
    "| **title_&_text**                   | object    | Title and text content with punctuations removed      |\n",
    "| **title_text_stemmed**             | object    | Title and text content after stemming                 |\n",
    "| **title_text_lemmatized**          | object    | Title and text content after lemmatization            |\n",
    "| **stemmed_round_1**                | object    | Stemmed title and text after 1st round of feature engineering|\n",
    "| **lemmatized_round_1**             | object    | Lemmatized title and text after 1st round of feature engineering|\n",
    "| **stemmed_round_2**                | object    | Stemmed title and text after 2nd round of feature engineering|\n",
    "| **lemmatized_round_2**             | object    | Lemmatized title and text after 2nd round of feature engineering|\n",
    "| **stemmed_round_3**                | object    | Stemmed title and text after 3rd round of feature engineering|\n",
    "| **lemmatized_round_3**             | object    | Lemmatized title and text after 3rd round of feature engineering|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c986f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data in 'reddit_raw.csv'\n",
    "all_posts.to_csv('reddit_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68b77d",
   "metadata": {},
   "source": [
    "**Next:** [Part 2 - Data Cleaning](Part%202%20-%20Data%20Cleaning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
